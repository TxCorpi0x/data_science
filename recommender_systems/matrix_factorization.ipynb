{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/tevfikaytekin/data_science/blob/master/recommender_systems/matrix_factorization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgs5IIoUSn9l"
   },
   "source": [
    "# Matrix Factorization\n",
    "(by Tevfik Aytekin)\n",
    "\n",
    "Matrix factorizarion is one of the state-of-the-art techniques used in recommender systems. Below you can find several different implementations.\n",
    "\n",
    "Over the years many variations of matrix factorization have been proposed. The following formulation is one of the simplest but which works well as we will see. It can be extended it various ways, see for example [Advances in Collaborative Filtering](https://link.springer.com/chapter/10.1007/978-1-4899-7637-6_3).\n",
    "\n",
    "Cost Function:\n",
    "$$\n",
    "J(\\Theta) =  \\sum_{u,i \\in K} (r_{ui} - q^T_ip_u)^2 + \\lambda(||q_i||^2+||p_u||^2)\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "- $r_{ui}$ is the rating of user $u$ for item $i$.\n",
    "- $K$ is the set of $(u,i)$ pairs for which $r_{ui}$ is known.\n",
    "- $q_i$, $p_u$ are latent factor vectors for items and users, respectively. \n",
    "- $\\lambda$ is the regularization parameter.\n",
    "\n",
    "And the optimization objective:\n",
    "\n",
    "$$\n",
    "\\min_{p*,q*} \\sum_{u,i \\in K} (r_{ui} - q^T_ip_u)^2 + \\lambda(||q_i||^2+||p_u||^2)\n",
    "$$\n",
    "\n",
    "Typically the optimization done with gradient descent. To apply it we need to first find the partial derivative of the cost function with respect to latent variables which we will denote as $q_{fi}$ and $p_{fu}$. We can find the partial derivative as: \n",
    "\n",
    "$$\n",
    "\\frac{\\partial J(\\Theta)}{\\partial p_{ku}}=-\\sum_{i \\in I_u}2(r_{ui} - q^T_ip_u)q_{ki} + 2\\lambda p_{ku}\n",
    "$$\n",
    "\n",
    "For **stochastic gradient descent** the update rule for the the $p_u$ vector for a single training example is:\n",
    "\n",
    "$$\n",
    "p_u = p_u + \\alpha ((r_{ui} - q^T_ip_u)q_{i} - \\lambda p_{u})\n",
    "$$\n",
    "\n",
    "similarly for $q_i$ vector we have:\n",
    "\n",
    "$$\n",
    "q_i = q_i + \\alpha ((r_{ui} - q^T_ip_u)p_{u} - \\lambda q_{u})\n",
    "$$\n",
    "\n",
    "For **batch gradient descent** the update rule for the the $p_u$ vector for all preferences where user $u$ appears:\n",
    "\n",
    "$$\n",
    "p_u = p_u + \\alpha (\\sum_{i \\in I_u}(r_{ui} - q^T_ip_u)q_{i} - \\lambda p_{u})\n",
    "$$\n",
    "\n",
    "similarly for $q_i$ vector we have:\n",
    "\n",
    "$$\n",
    "q_i = q_i + \\alpha (\\sum_{u \\in U_i} (r_{ui} - q^T_ip_u)p_{u} - \\lambda q_{u})\n",
    "$$\n",
    "\n",
    "In the above equations $I_u$ is the set of items rated by user $u$ and $U_i$ is the set of users who rated item $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "84apIe07Sn9q"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from scipy.sparse import csr_matrix\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzo9HTNYSn9r"
   },
   "source": [
    "# Movielens dataset\n",
    "\n",
    "We will use the smallest Movielens 100k Dataset which includes 100k preferences. A preference is a triple (user, item, rating). You can download this data set from\n",
    "[https://grouplens.org/datasets/movielens/](https://grouplens.org/datasets/movielens/)\n",
    "\n",
    "Note the sparsity of the dataset which shows that most of the user/item matrix is empty. This is a typical property of the datasets in this domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 470,
     "status": "ok",
     "timestamp": 1663599210587,
     "user": {
      "displayName": "Tevfik Aytekin",
      "userId": "03705756795675396046"
     },
     "user_tz": -180
    },
    "id": "JvZEZ2KFSn9r",
    "outputId": "b26ea5cb-8036-42b4-8243-1874704336ed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefs = pd.read_csv(\"/home/tevfik/Documents/datasets/ml-latest-small/ratings.csv\", sep=\",\")\n",
    "#prefs = pd.read_csv(\"ratings.csv\", sep=\",\")\n",
    "#prefs = pd.read_csv(\"drive/MyDrive/PycharmProjects/datasets/ml-latest-small/ratings.csv\", sep=\",\")\n",
    "\n",
    "prefs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 579,
     "status": "ok",
     "timestamp": 1663599222262,
     "user": {
      "displayName": "Tevfik Aytekin",
      "userId": "03705756795675396046"
     },
     "user_tz": -180
    },
    "id": "KNUNaoQSSn9s",
    "outputId": "244822bf-72ab-4131-fec1-f0ad8ef0a30f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 610\n",
      "Number of items: 9724\n",
      "Number of preferences: 100836\n",
      "Sparsity: 0.016999683055613623\n"
     ]
    }
   ],
   "source": [
    "n_users = prefs.iloc[:,0].unique().size\n",
    "n_items = prefs.iloc[:,1].unique().size\n",
    "n_prefs = prefs.iloc[:,1].size\n",
    "users = prefs.iloc[:,0].unique()\n",
    "items = prefs.iloc[:,1].unique()\n",
    "\n",
    "print(\"Number of users:\",n_users)\n",
    "print(\"Number of items:\",n_items)\n",
    "print(\"Number of preferences:\",n_prefs)\n",
    "print(\"Sparsity:\",n_prefs/(n_users*n_items))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9A6dD4keSn9t"
   },
   "source": [
    "### Error Function\n",
    "\n",
    "Error is calculated by predicting the rating of a user and an item in the test set using the factor representations of users and items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "R6xzCHN4Sn9t"
   },
   "outputs": [],
   "source": [
    "def calc_error(X, u_factors, i_factors):\n",
    "    error = 0\n",
    "    for i in range(X.shape[0]):\n",
    "        u_idx = X.iloc[i,0]\n",
    "        i_idx = X.iloc[i,1]\n",
    "        error += np.abs(X.iloc[i,2] - np.dot(u_factors[u_idx].T, i_factors[i_idx]))\n",
    "    return error/X.shape[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AE8UpWc1Sn9u"
   },
   "source": [
    "### Random Predictor Error\n",
    "\n",
    "**Exercise**: What is the expected error of a random predictor given that the actual ratings are uniformly distributed between 1 and 5?\n",
    "\n",
    "Below is a function for calculating this error experimentally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "NX4-hb8vSn9v"
   },
   "outputs": [],
   "source": [
    "def random_predictor_error(X):\n",
    "    error = 0\n",
    "    for i in range(X.shape[0]):\n",
    "        u_idx = X.iloc[i,0]\n",
    "        i_idx = X.iloc[i,1]\n",
    "        error += np.abs(X.iloc[i,2] - np.random.randint(1,6))\n",
    "    return error/X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "bvgyC1VJSn9v"
   },
   "outputs": [],
   "source": [
    "# initialize factor matrices\n",
    "n_factors = 5\n",
    "item_factors = {}\n",
    "user_factors = {}\n",
    "for r in range(n_prefs):\n",
    "    user_factors[prefs.iloc[r,0]] = np.random.rand(n_factors,1) - 0.5\n",
    "    item_factors[prefs.iloc[r,1]] = np.random.rand(n_factors,1) - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1663511703257,
     "user": {
      "displayName": "Tevfik Aytekin",
      "userId": "03705756795675396046"
     },
     "user_tz": -180
    },
    "id": "tN1NtOQISn9w",
    "outputId": "3187371e-4586-4f1d-fcf4-79cfd0388a3e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.11979976],\n",
       "       [-0.09314695],\n",
       "       [-0.42510215],\n",
       "       [ 0.09456017],\n",
       "       [-0.32070388]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_factors[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23479,
     "status": "ok",
     "timestamp": 1663511728591,
     "user": {
      "displayName": "Tevfik Aytekin",
      "userId": "03705756795675396046"
     },
     "user_tz": -180
    },
    "id": "qAVXvpFuSn9w",
    "outputId": "65041189-2e4f-4aad-c3f4-408684a7c4a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random predictor error:  1.4802749018207784\n"
     ]
    }
   ],
   "source": [
    "print(\"Random predictor error: \", random_predictor_error(prefs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HhCmDB3TSn9x"
   },
   "source": [
    "### Stochastic Gradient Descent\n",
    "\n",
    "Following is the stochastic gradient algorithm which is popularized by [Simon Funk](https://sifter.org/simon/journal/20061211.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 512
    },
    "executionInfo": {
     "elapsed": 88951,
     "status": "error",
     "timestamp": 1663511961996,
     "user": {
      "displayName": "Tevfik Aytekin",
      "userId": "03705756795675396046"
     },
     "user_tz": -180
    },
    "id": "_km686P-Sn9x",
    "outputId": "f1214f6d-aaad-4ef7-9c67-0b4b4f4a742c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error:  [[3.50119857]]\n",
      "Iteration  0\n",
      "Train error:  [[1.04724026]]\n",
      "Test error:  [[1.12198071]]\n",
      "Iteration  1\n",
      "Train error:  [[0.80947548]]\n",
      "Test error:  [[0.91300559]]\n",
      "Iteration  2\n",
      "Train error:  [[0.73427169]]\n",
      "Test error:  [[0.85732055]]\n",
      "Iteration  3\n",
      "Train error:  [[0.69932492]]\n",
      "Test error:  [[0.83645428]]\n",
      "Iteration  4\n",
      "Train error:  [[0.67963575]]\n",
      "Test error:  [[0.82241197]]\n"
     ]
    }
   ],
   "source": [
    "n_factors = 5\n",
    "item_factors = {}\n",
    "user_factors = {}\n",
    "for r in range(n_prefs):\n",
    "    user_factors[prefs.iloc[r,0]] = np.random.rand(n_factors,1) - 0.5\n",
    "    item_factors[prefs.iloc[r,1]] = np.random.rand(n_factors,1) - 0.5\n",
    "    \n",
    "X_train, X_test = train_test_split(prefs, test_size=0.1)\n",
    "\n",
    "# Stochastic Gradient descent\n",
    "alpha = 0.03\n",
    "my_lambda = 0.1\n",
    "n_iters = 5\n",
    "    \n",
    "print(\"Initial error: \", calc_error(X_train, user_factors, item_factors))\n",
    "\n",
    "for t in range(n_iters):\n",
    "    #q = 10\n",
    "    #ux = prefs.iloc[q,0]; ix = prefs.iloc[q,1]\n",
    "    #print(\"user factor: \",user_factors[ux],\"item factor: \", item_factors[ix])\n",
    "    #print(\"actual rating: \", prefs.iloc[q,2], \"predicted rating: \", np.dot(user_factors[ux].T,item_factors[ix]))\n",
    "    X_train = shuffle(X_train)\n",
    "    for r in range(X_train.shape[0]):\n",
    "        u = X_train.iloc[r,0]\n",
    "        i = X_train.iloc[r,1]\n",
    "        error = X_train.iloc[r,2] - np.dot(user_factors[u].T, item_factors[i])[0,0]\n",
    "        user_factors[u] = user_factors[u] + alpha*(error*item_factors[i] - my_lambda*user_factors[u])\n",
    "        item_factors[i] = item_factors[i] + alpha*(error*user_factors[u] - my_lambda*item_factors[i])  \n",
    "       \n",
    "          \n",
    "    print(\"Iteration \", t)\n",
    "    print(\"Train error: \", calc_error(X_train, user_factors, item_factors))\n",
    "    print(\"Test error: \", calc_error(X_test, user_factors, item_factors))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to make a prediction?\n",
    "Once the user and item factors are learned you can make a prediction for any user and item pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0223775 ],\n",
       "       [-0.3111142 ],\n",
       "       [-0.80764908],\n",
       "       [ 0.12634261],\n",
       "       [ 1.07515975]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_factors[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.56532791],\n",
       "       [-0.12872923],\n",
       "       [-1.21287299],\n",
       "       [ 0.2411651 ],\n",
       "       [ 1.03796345]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_factors[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.86508616]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(user_factors[10].T, item_factors[50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgGw4j4GSn9y"
   },
   "source": [
    "### Batch Gradient Descent\n",
    "If you run the code below you will see that both training and test errors decrease very slowly. Eventually there will be convergence but compared to stochastic version it will be very slow. It is a good example to show the speed advantage of stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 654
    },
    "executionInfo": {
     "elapsed": 150922,
     "status": "error",
     "timestamp": 1663512327284,
     "user": {
      "displayName": "Tevfik Aytekin",
      "userId": "03705756795675396046"
     },
     "user_tz": -180
    },
    "id": "MdUJbtKBSn9y",
    "outputId": "30deb2e4-31ee-4bbe-889e-023e6b47aa3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  0\n",
      "Train error:  [[3.48679096]]\n",
      "Test error:  [[3.50851927]]\n",
      "Iteration  1\n",
      "Train error:  [[3.47311008]]\n",
      "Test error:  [[3.50814783]]\n",
      "Iteration  2\n",
      "Train error:  [[3.45820314]]\n",
      "Test error:  [[3.50708082]]\n",
      "Iteration  3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/tevfik/Documents/data_science/recommender_systems/matrix_factorization.ipynb Cell 21\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tevfik/Documents/data_science/recommender_systems/matrix_factorization.ipynb#X24sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     item_factors[i] \u001b[39m=\u001b[39m item_factors[i] \u001b[39m+\u001b[39m alpha\u001b[39m*\u001b[39m(sum_total \u001b[39m-\u001b[39m my_lambda\u001b[39m*\u001b[39mitem_factors[i])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tevfik/Documents/data_science/recommender_systems/matrix_factorization.ipynb#X24sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mIteration \u001b[39m\u001b[39m\"\u001b[39m, t)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/tevfik/Documents/data_science/recommender_systems/matrix_factorization.ipynb#X24sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTrain error: \u001b[39m\u001b[39m\"\u001b[39m, calc_error(X_train,user_factors,item_factors))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tevfik/Documents/data_science/recommender_systems/matrix_factorization.ipynb#X24sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTest error: \u001b[39m\u001b[39m\"\u001b[39m, calc_error(X_test,user_factors,item_factors))\n",
      "\u001b[1;32m/home/tevfik/Documents/data_science/recommender_systems/matrix_factorization.ipynb Cell 21\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tevfik/Documents/data_science/recommender_systems/matrix_factorization.ipynb#X24sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     u_idx \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39miloc[i,\u001b[39m0\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tevfik/Documents/data_science/recommender_systems/matrix_factorization.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     i_idx \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39miloc[i,\u001b[39m1\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/tevfik/Documents/data_science/recommender_systems/matrix_factorization.ipynb#X24sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     error \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mabs(X\u001b[39m.\u001b[39miloc[i,\u001b[39m2\u001b[39m] \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39;49mdot(u_factors[u_idx]\u001b[39m.\u001b[39;49mT, i_factors[i_idx]))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tevfik/Documents/data_science/recommender_systems/matrix_factorization.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mreturn\u001b[39;00m error\u001b[39m/\u001b[39mX\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m<__array_function__ internals>:179\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "import copy\n",
    "#initialize factor matrices\n",
    "item_factors = {}\n",
    "user_factors = {}\n",
    "for i in range(n_prefs):\n",
    "    user_factors[prefs.iloc[i,0]] = np.random.rand(n_factors,1) - 0.5\n",
    "    item_factors[prefs.iloc[i,1]] = np.random.rand(n_factors,1) - 0.5\n",
    "    \n",
    "X_train, X_test = train_test_split(prefs, test_size=0.1)\n",
    "\n",
    "train_users = X_train.iloc[:,0].unique()\n",
    "train_items = X_train.iloc[:,1].unique()\n",
    "R = csr_matrix((X_train.iloc[:,2], (X_train.iloc[:,0],X_train.iloc[:,1])))\n",
    "\n",
    "# Batch Gradient descent\n",
    "alpha = 0.1\n",
    "my_lambda = 0.1\n",
    "n_iters = 100\n",
    "\n",
    "for t in range(n_iters):\n",
    "    for u in train_users:\n",
    "        I_u = X_train[X_train.userId==u].iloc[:,1]\n",
    "        sum_total = 0\n",
    "        for i in I_u:\n",
    "            sum_total += (R[u,i] - np.dot(item_factors[i].T, user_factors[u])[0,0])*item_factors[i]\n",
    "        sum_total = sum_total / I_u.size\n",
    "        user_factors[u] = user_factors[u] + alpha*(sum_total - my_lambda*user_factors[u])\n",
    "    for i in train_items:\n",
    "        U_i = X_train[X_train.movieId==i].iloc[:,0]\n",
    "        sum_total = 0\n",
    "        for u in U_i:\n",
    "            sum_total += (R[u,i] - np.dot(item_factors[i].T, user_factors[u])[0,0])*user_factors[u]\n",
    "        sum_total = sum_total / U_i.size\n",
    "        item_factors[i] = item_factors[i] + alpha*(sum_total - my_lambda*item_factors[i])\n",
    "        \n",
    "    print(\"Iteration \", t)\n",
    "    print(\"Train error: \", calc_error(X_train,user_factors,item_factors))\n",
    "    print(\"Test error: \", calc_error(X_test,user_factors,item_factors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OcgyM8a9Sn9y"
   },
   "source": [
    "### Question\n",
    "\n",
    "Suppose that user A appears in 200 rows in the user-item preferences dataset. In a single epoch how many updates will there be to the latent vector $p_u$ in stochastic GD vs. Batch GD?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOwthAvMSn9y"
   },
   "source": [
    "### Alternating Least Squares (ALS)\n",
    "Since the datasets in this domain are really large, people always try to find ways to speed up the optimization processes. One popular algorithm is called ALS. Here the basic idea is that although the cost function is not convex, when either user factors or items factors are fixed then it becomes a convex function which can be directly solved. The algorithm alternates between updating user and item factors. ([Large-scale parallel collaborative filtering for the netflix prize](https://link.springer.com/chapter/10.1007/978-3-540-68880-8_32)). \n",
    "\n",
    "$$\n",
    "\\frac{\\partial J(\\Theta)}{\\partial p_{ku}}=-\\sum_{i \\in I_u}2(r_{ui} - q^T_ip_u)q_{ki} + 2\\lambda p_{ku} = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sum_{i \\in I_u} q_{ki}q^T_ip_u + \\lambda p_{ku} = \\sum_{i \\in I_u}q_{ki}r_{ui} \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sum_{i \\in I_u} q_{i}q^T_ip_u + \\lambda p_{u} = \\sum_{i \\in I_u}q_{i}r_{ui} \n",
    "$$\n",
    "\n",
    "$$\n",
    "(Q_{I_u}Q_{I_u}^T + \\lambda I) p_{u} = Q_{I_u}R^T(u,I_u)\n",
    "$$\n",
    "\n",
    "$$\n",
    "p_{u} = (Q_{I_u}Q_{I_u}^T + \\lambda I)^{-1}Q_{I_u}R^T(u,I_u)\n",
    "$$\n",
    "\n",
    "where $I$ is the $f × f$ identity matrix. $Q_{I_u}$ denotes the sub-matrix of $Q$ where columns $j \\in I_u$ are selected, and $R^T(u,I_u)$ is the row vector where columns $j \\in I_u$ of the $u$-th row of $R$ are selected.\n",
    "\n",
    "Similarly for $q_i$ we have:\n",
    "\n",
    "$$\n",
    "q_{i} = (P_{U_i}P_{U_i}^T + \\lambda I)^{-1}P_{U_i}R(U_i,i)\n",
    "$$\n",
    "\n",
    "where $I$ is the $f × f$ identity matrix. $P_{U_i}$ denotes the sub-matrix of $P$ where columns $j \\in U_i$ are selected, and $R(U_i,i)$ is the column vector where columns $j \\in U_i$ of the $i$-th column of $R$ are selected.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "mqRNL5UASn9z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  0\n",
      "Train error:  2.007204001449057\n",
      "Test error:  3.0777682475972528\n",
      "Iteration  1\n",
      "Train error:  0.8191487562109738\n",
      "Test error:  1.2703678764134934\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/tevfik/Documents/data_science/recommender_systems/matrix_factorization.ipynb Cell 24\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tevfik/Documents/data_science/recommender_systems/matrix_factorization.ipynb#X30sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mfor\u001b[39;00m u \u001b[39min\u001b[39;00m train_users:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tevfik/Documents/data_science/recommender_systems/matrix_factorization.ipynb#X30sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     I_u \u001b[39m=\u001b[39m X_train[X_train\u001b[39m.\u001b[39muserId\u001b[39m==\u001b[39mu]\u001b[39m.\u001b[39miloc[:,\u001b[39m1\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/tevfik/Documents/data_science/recommender_systems/matrix_factorization.ipynb#X30sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     A \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(Q[I_u],Q[I_u]\u001b[39m.\u001b[39mT)\u001b[39m+\u001b[39mmy_lambda\u001b[39m*\u001b[39mnp\u001b[39m.\u001b[39midentity(n_factors)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tevfik/Documents/data_science/recommender_systems/matrix_factorization.ipynb#X30sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     V \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(Q[I_u],R[u,I_u]\u001b[39m.\u001b[39mtodense()\u001b[39m.\u001b[39mT)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tevfik/Documents/data_science/recommender_systems/matrix_factorization.ipynb#X30sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     P[u] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39minv(A),V)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3773\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3770\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(indexer, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m   3771\u001b[0m     indexer \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(indexer)[\u001b[39m0\u001b[39m]\n\u001b[0;32m-> 3773\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take_with_is_copy(indexer, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m   3775\u001b[0m \u001b[39mif\u001b[39;00m is_single_key:\n\u001b[1;32m   3776\u001b[0m     \u001b[39m# What does looking for a single key in a non-unique index return?\u001b[39;00m\n\u001b[1;32m   3777\u001b[0m     \u001b[39m# The behavior is inconsistent. It returns a Series, except when\u001b[39;00m\n\u001b[1;32m   3778\u001b[0m     \u001b[39m# - the key itself is repeated (test on data.shape, #9519), or\u001b[39;00m\n\u001b[1;32m   3779\u001b[0m     \u001b[39m# - we have a MultiIndex on columns (test on self.columns, #21309)\u001b[39;00m\n\u001b[1;32m   3780\u001b[0m     \u001b[39mif\u001b[39;00m data\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n\u001b[1;32m   3781\u001b[0m         \u001b[39m# GH#26490 using data[key] can cause RecursionError\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:3948\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   3940\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_take_with_is_copy\u001b[39m(\u001b[39mself\u001b[39m: NDFrameT, indices, axis: Axis \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NDFrameT:\n\u001b[1;32m   3941\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3942\u001b[0m \u001b[39m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[1;32m   3943\u001b[0m \u001b[39m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3946\u001b[0m \u001b[39m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[1;32m   3947\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3948\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take(indices\u001b[39m=\u001b[39;49mindices, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   3949\u001b[0m     \u001b[39m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[1;32m   3950\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m result\u001b[39m.\u001b[39m_get_axis(axis)\u001b[39m.\u001b[39mequals(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:3932\u001b[0m, in \u001b[0;36mNDFrame._take\u001b[0;34m(self, indices, axis, convert_indices)\u001b[0m\n\u001b[1;32m   3924\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   3925\u001b[0m         axis \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m   3926\u001b[0m         \u001b[39mand\u001b[39;00m indices\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   3927\u001b[0m         \u001b[39mand\u001b[39;00m using_copy_on_write()\n\u001b[1;32m   3928\u001b[0m         \u001b[39mand\u001b[39;00m is_range_indexer(indices, \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m))\n\u001b[1;32m   3929\u001b[0m     ):\n\u001b[1;32m   3930\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[0;32m-> 3932\u001b[0m new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mtake(\n\u001b[1;32m   3933\u001b[0m     indices,\n\u001b[1;32m   3934\u001b[0m     axis\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_block_manager_axis(axis),\n\u001b[1;32m   3935\u001b[0m     verify\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   3936\u001b[0m     convert_indices\u001b[39m=\u001b[39;49mconvert_indices,\n\u001b[1;32m   3937\u001b[0m )\n\u001b[1;32m   3938\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(new_data)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtake\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/internals/managers.py:963\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[0;34m(self, indexer, axis, verify, convert_indices)\u001b[0m\n\u001b[1;32m    960\u001b[0m     indexer \u001b[39m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[39m=\u001b[39mverify)\n\u001b[1;32m    962\u001b[0m new_labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis]\u001b[39m.\u001b[39mtake(indexer)\n\u001b[0;32m--> 963\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreindex_indexer(\n\u001b[1;32m    964\u001b[0m     new_axis\u001b[39m=\u001b[39;49mnew_labels,\n\u001b[1;32m    965\u001b[0m     indexer\u001b[39m=\u001b[39;49mindexer,\n\u001b[1;32m    966\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    967\u001b[0m     allow_dups\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    968\u001b[0m     copy\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    969\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/internals/managers.py:740\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    737\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mRequested axis not found in manager\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    739\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 740\u001b[0m     new_blocks \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_slice_take_blocks_ax0(\n\u001b[1;32m    741\u001b[0m         indexer,\n\u001b[1;32m    742\u001b[0m         fill_value\u001b[39m=\u001b[39;49mfill_value,\n\u001b[1;32m    743\u001b[0m         only_slice\u001b[39m=\u001b[39;49monly_slice,\n\u001b[1;32m    744\u001b[0m         use_na_proxy\u001b[39m=\u001b[39;49muse_na_proxy,\n\u001b[1;32m    745\u001b[0m     )\n\u001b[1;32m    746\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    747\u001b[0m     new_blocks \u001b[39m=\u001b[39m [\n\u001b[1;32m    748\u001b[0m         blk\u001b[39m.\u001b[39mtake_nd(\n\u001b[1;32m    749\u001b[0m             indexer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[39mfor\u001b[39;00m blk \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks\n\u001b[1;32m    756\u001b[0m     ]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/internals/managers.py:898\u001b[0m, in \u001b[0;36mBaseBlockManager._slice_take_blocks_ax0\u001b[0;34m(self, slice_or_indexer, fill_value, only_slice, use_na_proxy)\u001b[0m\n\u001b[1;32m    896\u001b[0m                     blocks\u001b[39m.\u001b[39mappend(nb)\n\u001b[1;32m    897\u001b[0m             \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 898\u001b[0m                 nb \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39;49mtake_nd(taker, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, new_mgr_locs\u001b[39m=\u001b[39;49mmgr_locs)\n\u001b[1;32m    899\u001b[0m                 blocks\u001b[39m.\u001b[39mappend(nb)\n\u001b[1;32m    901\u001b[0m \u001b[39mreturn\u001b[39;00m blocks\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/internals/blocks.py:945\u001b[0m, in \u001b[0;36mBlock.take_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[1;32m    942\u001b[0m     allow_fill \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[39m# Note: algos.take_nd has upcast logic similar to coerce_to_target_dtype\u001b[39;00m\n\u001b[0;32m--> 945\u001b[0m new_values \u001b[39m=\u001b[39m algos\u001b[39m.\u001b[39;49mtake_nd(\n\u001b[1;32m    946\u001b[0m     values, indexer, axis\u001b[39m=\u001b[39;49maxis, allow_fill\u001b[39m=\u001b[39;49mallow_fill, fill_value\u001b[39m=\u001b[39;49mfill_value\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    949\u001b[0m \u001b[39m# Called from three places in managers, all of which satisfy\u001b[39;00m\n\u001b[1;32m    950\u001b[0m \u001b[39m#  these assertions\u001b[39;00m\n\u001b[1;32m    951\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ExtensionBlock):\n\u001b[1;32m    952\u001b[0m     \u001b[39m# NB: in this case, the 'axis' kwarg will be ignored in the\u001b[39;00m\n\u001b[1;32m    953\u001b[0m     \u001b[39m#  algos.take_nd call above.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/array_algos/take.py:117\u001b[0m, in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\u001b[39m.\u001b[39mtake(indexer, fill_value\u001b[39m=\u001b[39mfill_value, allow_fill\u001b[39m=\u001b[39mallow_fill)\n\u001b[1;32m    116\u001b[0m arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(arr)\n\u001b[0;32m--> 117\u001b[0m \u001b[39mreturn\u001b[39;00m _take_nd_ndarray(arr, indexer, axis, fill_value, allow_fill)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/array_algos/take.py:155\u001b[0m, in \u001b[0;36m_take_nd_ndarray\u001b[0;34m(arr, indexer, axis, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m    149\u001b[0m out_shape \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(out_shape_)\n\u001b[1;32m    150\u001b[0m \u001b[39mif\u001b[39;00m arr\u001b[39m.\u001b[39mflags\u001b[39m.\u001b[39mf_contiguous \u001b[39mand\u001b[39;00m axis \u001b[39m==\u001b[39m arr\u001b[39m.\u001b[39mndim \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    151\u001b[0m     \u001b[39m# minor tweak that can make an order-of-magnitude difference\u001b[39;00m\n\u001b[1;32m    152\u001b[0m     \u001b[39m# for dataframes initialized directly from 2-d ndarrays\u001b[39;00m\n\u001b[1;32m    153\u001b[0m     \u001b[39m# (s.t. df.values is c-contiguous and df._mgr.blocks[0] is its\u001b[39;00m\n\u001b[1;32m    154\u001b[0m     \u001b[39m# f-contiguous transpose)\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m     out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mempty(out_shape, dtype\u001b[39m=\u001b[39;49mdtype, order\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mF\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    156\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    157\u001b[0m     out \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty(out_shape, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#initialize factor matrices\n",
    "n_factors = 5\n",
    "\n",
    "Q = pd.DataFrame(np.random.rand(n_factors,n_items)-0.5, columns=items)\n",
    "P = pd.DataFrame(np.random.rand(n_factors,n_users)-0.5, columns=users)\n",
    "\n",
    "X_train, X_test = train_test_split(prefs, test_size=0.1)\n",
    "\n",
    "train_users = X_train.iloc[:,0].unique()\n",
    "train_items = X_train.iloc[:,1].unique()\n",
    "R = csr_matrix((X_train.iloc[:,2], (X_train.iloc[:,0],X_train.iloc[:,1])))\n",
    "\n",
    "alpha = 0.030\n",
    "my_lambda = 0.1\n",
    "n_iters = 100\n",
    "\n",
    "for t in range(n_iters):\n",
    "    for u in train_users:\n",
    "        I_u = X_train[X_train.userId==u].iloc[:,1]\n",
    "        A = np.dot(Q[I_u],Q[I_u].T)+my_lambda*np.identity(n_factors)\n",
    "        V = np.dot(Q[I_u],R[u,I_u].todense().T)\n",
    "        P[u] = np.dot(np.linalg.inv(A),V)\n",
    "    for i in train_items:\n",
    "        U_i = X_train[X_train.movieId==i].iloc[:,0]\n",
    "        A = np.dot(P[U_i],P[U_i].T)+my_lambda*np.identity(n_factors)\n",
    "        V = np.dot(P[U_i],R[U_i,i].todense())     \n",
    "        Q[i] = np.dot(np.linalg.inv(A),V)\n",
    "        \n",
    "    print(\"Iteration \", t)\n",
    "    print(\"Train error: \", calc_error(X_train,P,Q))\n",
    "    print(\"Test error: \", calc_error(X_test,P,Q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "KXgt5udkSn90"
   },
   "outputs": [],
   "source": [
    "## The following has not yet finished\n",
    "\n",
    "class MF:\n",
    "    \"\"\"\n",
    "    prefs: matrix of prefences, column0=userid, column1=itemid, column2=pref, column3=timestamp \n",
    "    \"\"\"\n",
    "    def __init__(self, prefs, alpha=0.03, mylambda=0.1, n_factors = 10, n_iters = 50):\n",
    "        self.alpha = alpha\n",
    "        self.mylambda = mylambda\n",
    "        self.n_iters = n_iters\n",
    "        self.item_factors = {}\n",
    "        self.user_factors = {}\n",
    "        self.prefs = prefs\n",
    "        # prefs is a matrix containing u, i, r values in each row. This is useful to shuffle and pass over\n",
    "        # the data multiple times in an efficient way in the fit() method.\n",
    "        for r in range(self.prefs.shape[0]):\n",
    "            self.user_factors[self.prefs.iloc[r,0]] = np.random.rand(n_factors,1) - 0.5\n",
    "            self.item_factors[self.prefs.iloc[r,1]] = np.random.rand(n_factors,1) - 0.5\n",
    "        print(\"Finished initialization\")\n",
    "        \n",
    "     \n",
    "    def calc_error(self, X):\n",
    "        error = 0\n",
    "        for i in range(X.shape[0]):\n",
    "            u_idx = X.iloc[i,0]\n",
    "            i_idx = X.iloc[i,1]\n",
    "            error += np.abs(X.iloc[i,2] - np.dot(self.user_factors[u_idx].T, self.item_factors[i_idx]))\n",
    "        return error/self.prefs.shape[0]\n",
    "        \n",
    "    def fit(self, verbose=False, method=\"SGD\"):\n",
    "        if (method == \"Random\"):\n",
    "            error = 0\n",
    "            for i in range(prefs.shape[0]):\n",
    "                u_idx = prefs.iloc[i,0]\n",
    "                i_idx = prefs.iloc[i,1]\n",
    "                error += np.abs(prefs.iloc[i,2] - np.random.randint(1,6))\n",
    "            return error/prefs.shape[0]\n",
    "            \n",
    "        elif (method == \"SGD\"):\n",
    "            if (verbose): \n",
    "                print(\"Initial error: \", self.calc_error(prefs))                      \n",
    "            for t in range(self.n_iters):\n",
    "                self.prefs = shuffle(self.prefs)\n",
    "                for r in range(self.prefs.shape[0]):\n",
    "                    u = self.prefs.iloc[r,0]\n",
    "                    i = self.prefs.iloc[r,1]\n",
    "                    error = self.prefs.iloc[r,2] - np.dot(self.user_factors[u].T, self.item_factors[i])[0,0]\n",
    "                    self.user_factors[u] = self.user_factors[u] + self.alpha*(error*self.item_factors[i] - self.mylambda*self.user_factors[u])\n",
    "                    self.item_factors[i] = self.item_factors[i] + self.alpha*(error*self.user_factors[u] - self.mylambda*self.item_factors[i])  \n",
    "            \n",
    "                if (verbose): \n",
    "                    print(\"Iteration: \", t)\n",
    "                if (verbose): \n",
    "                    print(\"Train error: \", self.calc_error(self.prefs))                      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "nHyb23UT0QZ5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished initialization\n",
      "Random Predictor Error: [[3.50133057]]\n",
      "Initial error:  None\n",
      "Iteration:  0\n",
      "Random Predictor Error: [[0.97004331]]\n",
      "Train error:  None\n",
      "Iteration:  1\n",
      "Random Predictor Error: [[0.77222596]]\n",
      "Train error:  None\n",
      "Iteration:  2\n",
      "Random Predictor Error: [[0.71212855]]\n",
      "Train error:  None\n",
      "Iteration:  3\n",
      "Random Predictor Error: [[0.67955195]]\n",
      "Train error:  None\n",
      "Iteration:  4\n",
      "Random Predictor Error: [[0.65899879]]\n",
      "Train error:  None\n",
      "Iteration:  5\n",
      "Random Predictor Error: [[0.63166851]]\n",
      "Train error:  None\n",
      "Iteration:  6\n",
      "Random Predictor Error: [[0.62009774]]\n",
      "Train error:  None\n",
      "Iteration:  7\n",
      "Random Predictor Error: [[0.60613902]]\n",
      "Train error:  None\n",
      "Iteration:  8\n",
      "Random Predictor Error: [[0.59523205]]\n",
      "Train error:  None\n",
      "Iteration:  9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/tevfik/Documents/data_science/recommender_systems/matrix_factorization.ipynb Cell 27\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tevfik/Documents/data_science/recommender_systems/matrix_factorization.ipynb#X34sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m mf \u001b[39m=\u001b[39m MF(prefs)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/tevfik/Documents/data_science/recommender_systems/matrix_factorization.ipynb#X34sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m mf\u001b[39m.\u001b[39;49mfit(verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mSGD\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32m/home/tevfik/Documents/data_science/recommender_systems/matrix_factorization.ipynb Cell 27\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tevfik/Documents/data_science/recommender_systems/matrix_factorization.ipynb#X34sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mIteration: \u001b[39m\u001b[39m\"\u001b[39m, t)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tevfik/Documents/data_science/recommender_systems/matrix_factorization.ipynb#X34sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m \u001b[39mif\u001b[39;00m (verbose): \n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/tevfik/Documents/data_science/recommender_systems/matrix_factorization.ipynb#X34sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTrain error: \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcalc_error(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprefs))\n",
      "\u001b[1;32m/home/tevfik/Documents/data_science/recommender_systems/matrix_factorization.ipynb Cell 27\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tevfik/Documents/data_science/recommender_systems/matrix_factorization.ipynb#X34sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m error \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tevfik/Documents/data_science/recommender_systems/matrix_factorization.ipynb#X34sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/tevfik/Documents/data_science/recommender_systems/matrix_factorization.ipynb#X34sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     u_idx \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39;49miloc[i,\u001b[39m0\u001b[39;49m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tevfik/Documents/data_science/recommender_systems/matrix_factorization.ipynb#X34sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     i_idx \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39miloc[i,\u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/tevfik/Documents/data_science/recommender_systems/matrix_factorization.ipynb#X34sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     error \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mabs(X\u001b[39m.\u001b[39miloc[i,\u001b[39m2\u001b[39m] \u001b[39m-\u001b[39m np\u001b[39m.\u001b[39mdot(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39muser_factors[u_idx]\u001b[39m.\u001b[39mT, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem_factors[i_idx]))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/indexing.py:1096\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1094\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(com\u001b[39m.\u001b[39mapply_if_callable(x, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m key)\n\u001b[1;32m   1095\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m-> 1096\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49m_get_value(\u001b[39m*\u001b[39;49mkey, takeable\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_takeable)\n\u001b[1;32m   1097\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_tuple(key)\n\u001b[1;32m   1098\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1099\u001b[0m     \u001b[39m# we by definition only have the 0th axis\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3867\u001b[0m, in \u001b[0;36mDataFrame._get_value\u001b[0;34m(self, index, col, takeable)\u001b[0m\n\u001b[1;32m   3848\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3849\u001b[0m \u001b[39mQuickly retrieve single value at passed column and index.\u001b[39;00m\n\u001b[1;32m   3850\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3864\u001b[0m \u001b[39m`self.columns._index_as_unique`; Caller is responsible for checking.\u001b[39;00m\n\u001b[1;32m   3865\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3866\u001b[0m \u001b[39mif\u001b[39;00m takeable:\n\u001b[0;32m-> 3867\u001b[0m     series \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_ixs(col, axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m   3868\u001b[0m     \u001b[39mreturn\u001b[39;00m series\u001b[39m.\u001b[39m_values[index]\n\u001b[1;32m   3870\u001b[0m series \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_item_cache(col)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3667\u001b[0m, in \u001b[0;36mDataFrame._ixs\u001b[0;34m(self, i, axis)\u001b[0m\n\u001b[1;32m   3664\u001b[0m label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns[i]\n\u001b[1;32m   3666\u001b[0m col_mgr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mgr\u001b[39m.\u001b[39miget(i)\n\u001b[0;32m-> 3667\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_box_col_values(col_mgr, i)\n\u001b[1;32m   3669\u001b[0m \u001b[39m# this is a cached value, mark it so\u001b[39;00m\n\u001b[1;32m   3670\u001b[0m result\u001b[39m.\u001b[39m_set_as_cached(label, \u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:4235\u001b[0m, in \u001b[0;36mDataFrame._box_col_values\u001b[0;34m(self, values, loc)\u001b[0m\n\u001b[1;32m   4233\u001b[0m klass \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor_sliced\n\u001b[1;32m   4234\u001b[0m \u001b[39m# We get index=self.index bc values is a SingleDataManager\u001b[39;00m\n\u001b[0;32m-> 4235\u001b[0m \u001b[39mreturn\u001b[39;00m klass(values, name\u001b[39m=\u001b[39;49mname, fastpath\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/series.py:383\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m    369\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    370\u001b[0m     data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    375\u001b[0m     fastpath: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    376\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    377\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    378\u001b[0m         \u001b[39misinstance\u001b[39m(data, (SingleBlockManager, SingleArrayManager))\n\u001b[1;32m    379\u001b[0m         \u001b[39mand\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    380\u001b[0m         \u001b[39mand\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    381\u001b[0m         \u001b[39mand\u001b[39;00m (copy \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m copy \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    382\u001b[0m     ):\n\u001b[0;32m--> 383\u001b[0m         \u001b[39mif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    384\u001b[0m             data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    385\u001b[0m         \u001b[39m# GH#33357 called with just the SingleBlockManager\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mf = MF(prefs)\n",
    "mf.fit(verbose=True, method=\"SGD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jk47h4VO05Wx"
   },
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(prefs, test_size=0.1)\n",
    "mf = MF(X_train, n_iters=3)\n",
    "mf.fit(verbose=True, method=\"SGD\")\n",
    "print(\"Test error: \", mf.calc_error(X_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kuBrKXzppkp4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
